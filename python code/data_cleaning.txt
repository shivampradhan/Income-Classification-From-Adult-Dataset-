


# In[1]:LIBRARY IMPORTING


import numpy as np
import pandas as pd
import seaborn as sns
pd.options.mode.chained_assignment = None 
np.random.seed(30)


# In[2]:DATA LOADING


raw_data = pd.read_csv(r"D:\Shivam\Upwork\JoleneMartin\1\data\raw\upwork_data_1.csv")
print(raw_data.shape)
raw_data.head()


# In[3]:CHECKING Nan value


raw_data.isna().sum(axis = 0)


 Checking and removing duplicate rows as it wont help the model train

# In[4]:CHECKING DUPLICATE


duplicate=raw_data[raw_data.duplicated(subset=None, keep='first')]
print(duplicate.shape)
#duplicate


# In[5]:REMOVING DUPLICATE


unique_data=raw_data.drop_duplicates( keep='first', inplace=False)
print(unique_data.shape)
#unique_data


 

# In[6]:Checking na


unique_data.isnull().sum(axis = 0)


# ## 

# In[7]:Removing data with na in over_50k as we cant fill it because it is the Target variable


output_na=unique_data[unique_data['over_50k'].isna()]
output_na['over_50k'].isna().count()



input_data=unique_data[~unique_data['over_50k'].isna()]
input_data.shape


# ## so actual  input data we have is 26277 rows

# #

# In[9]: correcting wrong label for white in race


print(input_data.groupby('race')['id'].count())


# In[10]:renaming whi t e 

#input_data.loc[input_data.race == 'Whi t e','Whi t e'] = 'White'
input_data['race'][input_data.race == 'Whi t e'] = 'White'

print(input_data.groupby('race')['id'].count())


# ## 

# In[11]:dealing with wrong data of age -1


sns.distplot(input_data.age)


# In[12]:CHECKING NO OF AGE LESS THAN ZERO


c=input_data[input_data['age']<0]['age'].count()
print(f"Age less than zero in dataset {c}")


# In[13]:CHECKING NO OF AGE LESS THAN ZERO AND SALARY LESS THAN 50K


input_data[(input_data['age']<22) & (input_data['over_50k']=='<=50K')]['age'].count()


# In[14]:CHECKING PATTERN


x=input_data[(input_data['age']<22) & (input_data['over_50k']=='<=50K')]
#x.groupby('workclass').count() 2172
#x.groupby('marital_status').count() 2672
x.groupby('marital_status').count()
#y=input_data[(input_data['marital_status']=='Never-married')]
#list(y.groupby('age')['id'].count())


# ### most of the na in age are never  married 

# In[15]:


c=input_data[input_data['age']<0]['age'].count()
print(f"Age less than zero in dataset {c}")


# # age imputation of never married uniformly

# In[16]:RANDOM VALUE FILLED TO NEVER MARRIED PEOPLE WITH AGE -1


x=((input_data['age'] == -1) & (input_data['marital_status']=='Never-married'))

input_data.loc[((input_data['age'] == -1) & (input_data['marital_status']=='Never-married')),'age'] =np.random.randint(15,35, len(input_data.loc[((input_data['age'] == -1) & (input_data['marital_status']=='Never-married'))]))
sns.distplot(input_data.age)


# In[17]:COUNTING -1 AGE LEFT


c=input_data[input_data['age']<0]['age'].count()
print(f"Age less than zero in dataset {c}")


# In[18]:MARKING THEM AS NA


input_data['age'][input_data.age == -1] = np.nan
input_data['age'].isna().sum()


# In[19]:REMOVING THE DATASET WITH AGE NA


input_data=input_data[~input_data['age'].isna()]
input_data.shape


# ## 

# In[20]:Dealing with ? in data BY MARKING THEM NAN


input_data['native_country'][input_data.native_country == '?'] = np.nan
input_data['workclass'][input_data.workclass == '?'] = np.nan
input_data['occupation'][input_data.occupation == '?'] = np.nan


# In[21]:CHECKING CHANGES


workclass_q=input_data[input_data['workclass']=='?']['id'].count()
native_country_q=input_data[input_data['native_country']=='?']['id'].count()
occupation_q=input_data[input_data['occupation']=='?']['id'].count()
print (f"? in workclass is {workclass_q} native_country is {native_country_q} occupation is {occupation_q}")

# # total actual null 

# In[22]:CHECKING REMAINING NA


input_data.isna().sum().sum()


# In[23]:findinf rows with more than one variable having nan


input_data[
    (input_data['occupation'].isnull())
           |  (input_data['workclass'].isnull() ) 
           |  (input_data['native_country'].isnull())
         
           |  (input_data['education'].isnull())
        
]['id'].count() # 


# In[24]:rows with more than one variable having nan and also salary less than 50k
 



input_data[
    ((
        input_data['occupation'].isnull())
           |  (input_data['workclass'].isnull() ) 
           |  (input_data['native_country'].isnull())
        
           |  (input_data['education'].isnull())
          
    )
    
           & (input_data['over_50k']=='<=50K')
]['id'].count()


# 

# In[25]:dropping the null data ROWS  of over_50k not true area to help solving data imbalance


print(input_data['id'].count())
dropped_data=input_data[~
    ((
        (input_data['occupation'].isnull())
           |  (input_data['workclass'].isnull() )
           |  (input_data['native_country'].isnull())
           |  (input_data['education'].isnull())
    )
           
        
        & (input_data['over_50k']=='<=50K'))
]
dropped_data['id'].count()


# #

# In[26]: dealing with remaining NA


dropped_data[
    (dropped_data['education'].isnull()) 
           |  (dropped_data['workclass'].isnull() ) 
           |  (dropped_data['native_country'].isnull())
          
           |  (dropped_data['occupation'].isnull())
           #| (dropped_data['age']<0)
]['id'].count()


# In[27]:checking na count due to each variablr


workclass_q=dropped_data[dropped_data['workclass'].isnull()]['id'].count()
native_country_q=dropped_data[dropped_data['native_country'].isnull()]['id'].count()
occupation_q=dropped_data[dropped_data['occupation'].isnull()]['id'].count()
print (f"NA in workclass is {workclass_q} native_country is {native_country_q} occupation is {occupation_q}")


# ## 

# In[28]:Checking the common row in workclass and occupation NA


dropped_data[
            (   dropped_data['occupation'].isnull())
           & (dropped_data['workclass'].isnull() ) 
          ]['id'].count()


# In[29]:Dropping off the common row in workclass and occupation NA


print(input_data['id'].count())
dropped_data=dropped_data[~
    ((   dropped_data['occupation'].isnull())
           & (dropped_data['workclass'].isnull() ) )
]
dropped_data['id'].count()


# In[30]:checking change


workclass_q=dropped_data[dropped_data['workclass'].isnull()]['id'].count()
native_country_q=dropped_data[dropped_data['native_country'].isnull()]['id'].count()
occupation_q=dropped_data[dropped_data['occupation'].isnull()]['id'].count()
print (f"NA in workclass is {workclass_q} native_country is {native_country_q} occupation is {occupation_q}")




# # 

# In[31]: filling the remaining nan


print("nan left",dropped_data.isna().sum().sum())
mod=dropped_data['native_country'].mode()
dropped_data['native_country'][dropped_data.native_country.isnull()] = 'United-States'
print("nan left",dropped_data.isna().sum().sum())

dropped_data = dropped_data.fillna(dropped_data['education'].value_counts().index[0])
print("nan left",dropped_data.isna().sum().sum())


# In[32]:saving to a new datafrmae


data=dropped_data
data.shape


# # 

# In[33]:saving data to csv


data.to_csv(r'D:\Shivam\Upwork\JoleneMartin\1\data\processed\datacleaned.csv',index=False)



